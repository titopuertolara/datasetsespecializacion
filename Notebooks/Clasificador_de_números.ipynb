{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0x54AlZ_iMv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device='cuda:0'\n",
        "else:\n",
        "  device='cpu'"
      ],
      "metadata": {
        "id": "SmCCTzniA30y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir transformaciones para los datos de entrenamiento y prueba\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Descargar y cargar los datos de entrenamiento y prueba\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rdb3GAW2Ao7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la red neuronal\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)  # 1 input channel (grayscale), 6 output channels, 5x5 square convolution kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)  # 6 input channels, 16 output channels, 5x5 square convolution kernel\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)  # 16*5*5 input features, 120 output features\n",
        "        self.fc2 = nn.Linear(120, 84)  # 120 input features, 84 output features\n",
        "        self.fc3 = nn.Linear(84, 10)  # 84 input features, 10 output features (for the 10 classes of MNIST)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))  # Apply the first convolutional layer followed by ReLU activation\n",
        "        x = F.max_pool2d(x, 2)  # Apply 2x2 max pooling\n",
        "        x = F.relu(self.conv2(x))  # Apply the second convolutional layer followed by ReLU activation\n",
        "        x = F.max_pool2d(x, 2)  # Apply 2x2 max pooling\n",
        "        x = x.view(-1, 16*5*5)  # Flatten the tensor into a vector\n",
        "        x = F.relu(self.fc1(x))  # Apply the first fully connected layer followed by ReLU activation\n",
        "        x = F.relu(self.fc2(x))  # Apply the second fully connected layer followed by ReLU activation\n",
        "        x = self.fc3(x)  # Apply the final fully connected layer\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "nOHGReBIoAzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciar el modelo, el criterio de pérdida y el optimizador\n",
        "net = LeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "lsGPOPCuoCGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "epochs = 5\n",
        "net=net.train()\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs=inputs.to(device)\n",
        "        labels=labels.to(device)\n",
        "        optimizer.zero_grad()           # Limpiar los gradientes\n",
        "        outputs = net(inputs)           # Forward pass\n",
        "        loss = criterion(outputs, labels) # Calcular la pérdida\n",
        "        loss.backward()                 # Backward pass\n",
        "        optimizer.step()                # Optimización\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
        "\n",
        "# Evaluación del modelo\n",
        "correct = 0\n",
        "total = 0\n",
        "net=net.eval()\n",
        "for inputs, labels in testloader:\n",
        "    inputs=inputs.to(device)\n",
        "    labels=labels.to(device)\n",
        "    outputs = net(inputs)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {100 * correct / total}%\")"
      ],
      "metadata": {
        "id": "vE629N_XAM5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "indiv_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
        "i=0\n",
        "max_ejemp=10\n",
        "for image,label in indiv_loader:\n",
        "  if i<10:\n",
        "    res=net(image.to(device))\n",
        "    _,pred=torch.max(res,1)\n",
        "    print(50*'-')\n",
        "    print(f'Predicción: {pred.item()}')\n",
        "    cv2_imshow((255*image[0][0].numpy()).astype(np.uint8))\n",
        "    time.sleep(2)\n",
        "    i+=1\n",
        "  else:\n",
        "    print('Ha finalizado el demo')\n",
        "    break"
      ],
      "metadata": {
        "id": "GVMk4kJz_ouS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RDQoo7DzCidJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}