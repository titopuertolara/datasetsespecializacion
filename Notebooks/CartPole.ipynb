{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQAgent:\n",
    "    def __init__(self,env,state_size=4,action_size=2,discount_factor=0.95,epsilon_greedy=1,epsilon_min=0.01,epsilon_decay=0.995,learning_rate=1e-3,max_memory_size=500):\n",
    "        super(DeepQAgent,self).__init__()\n",
    "        self.env=env\n",
    "        self.epsilon=epsilon_greedy\n",
    "        self.epsilon_decay=epsilon_decay\n",
    "        self.learning_rate=learning_rate\n",
    "        self.epsilon_decay=epsilon_decay\n",
    "        self.state_size=state_size\n",
    "        self.action_size=action_size\n",
    "        self.gamma=discount_factor\n",
    "        self.epsilon_min=epsilon_min\n",
    "        self.build_model()\n",
    "        self.actions=[0,1]\n",
    "        self.memory=deque(maxlen=max_memory_size)\n",
    "    def build_model(self):\n",
    "        self.model=nn.Sequential(nn.Linear(self.state_size,256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(256,128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(128,64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(64,self.action_size))\n",
    "        self.loss_fn=nn.MSELoss()\n",
    "        self.optimizer=torch.optim.Adam(self.model.parameters(),self.learning_rate)\n",
    "    def remember(self,transition ):\n",
    "        self.memory.append(transition)\n",
    "    def choose_action(self,state):\n",
    "        if np.random.rand()<=self.epsilon:\n",
    "\n",
    "            return np.random.choice(self.actions)\n",
    "        else:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                q_values=self.model(torch.tensor(state,dtype=torch.float32))\n",
    "                #print(q_values)\n",
    "                return torch.argmax(q_values).item()\n",
    "    def learn(self,batch_samples):\n",
    "        batch_states,batch_targets=[],[]\n",
    "        for transition in batch_samples:\n",
    "            s,a,r,next_s,done=transition\n",
    "            with torch.no_grad():\n",
    "                if done:\n",
    "                    target=r\n",
    "                else:\n",
    "                    pred=self.model(torch.tensor(next_s,dtype=torch.float32))\n",
    "\n",
    "                    target=r+self.gamma*pred.max()\n",
    "\n",
    "                target_all=self.model(torch.tensor(s,dtype=torch.float32))\n",
    "                target_all[a]=target\n",
    "            batch_states.append(s)\n",
    "            batch_targets.append(target_all)\n",
    "            self.adjust_epsilon()\n",
    "        self.optimizer.zero_grad()\n",
    "        pred=self.model(torch.tensor(batch_states,dtype=torch.float32))\n",
    "        loss=self.loss_fn(pred,torch.stack(batch_targets))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "    def adjust_epsilon(self):\n",
    "        if self.epsilon>self.epsilon_min:\n",
    "            self.epsilon*=self.epsilon_decay\n",
    "    def replay(self,batch_size):\n",
    "        sample=random.sample(self.memory,batch_size)\n",
    "        return self.learn(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes=35\n",
    "batch_size=32\n",
    "memory_size=500\n",
    "env=gym.make('CartPole-v1',render_mode='human')\n",
    "agent=DeepQAgent(env)\n",
    "state=env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filling memory\")\n",
    "for i in range(memory_size):\n",
    "    action=agent.choose_action(state)\n",
    "    next_state,reward,done,_,_=env.step(action)\n",
    "    agent.remember((state,action,reward,next_state,done))\n",
    "    if done:\n",
    "        state=env.reset()[0]\n",
    "    else:\n",
    "        state=next_state\n",
    "total_rewards,losses=[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf65dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "for e in range(episodes):\n",
    "    state=env.reset()[0]\n",
    "    rewards=0\n",
    "    for j in range(500):\n",
    "        action=agent.choose_action(state)\n",
    "        next_state,reward,done,_,_=env.step(action)\n",
    "        agent.remember((state,action,reward,next_state,done))\n",
    "        state=next_state\n",
    "        rewards+=1\n",
    "        if done:\n",
    "            total_rewards.append(j)\n",
    "            print(f'Episode: {e} Total reward:{j} Epsilon:{agent.epsilon}')\n",
    "            break\n",
    "        loss=agent.replay(batch_size)\n",
    "        losses.append(loss)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "def moving_average(x, span=100):\n",
    "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
    "fig=go.Figure()\n",
    "fig.add_trace(go.Scatter(y=total_rewards,mode='lines+markers',name='Recompensa'))\n",
    "fig.add_trace(go.Scatter(y=moving_average(total_rewards),name='Tendencia'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d1a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
